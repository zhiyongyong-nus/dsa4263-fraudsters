{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KkT1YOn4F2PI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 1. LOAD DATA ==========\n",
        "train = pd.read_csv('/content/drive/MyDrive/dsa4263/2017_data.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/dsa4263/ddos2018_cleaned.csv')"
      ],
      "metadata": {
        "id": "iKQd6i4AQ9V4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only relevant columns\n",
        "graph_cols = ['Source IP', 'Destination IP', 'Label']\n",
        "feature_cols = [col for col in train.columns if col not in graph_cols + ['Flow ID', 'Timestamp']]\n",
        "\n",
        "# Drop rows with NaNs for now\n",
        "train = train.dropna(subset=graph_cols + feature_cols)\n",
        "test = test.dropna(subset=graph_cols + feature_cols)\n",
        "\n",
        "# Replace inf values\n",
        "train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute and scale features\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(imputer.fit_transform(train[feature_cols]))\n",
        "X_test = scaler.transform(imputer.transform(test[feature_cols]))\n",
        "\n",
        "# Label encoding: BENIGN or Benign â†’ 0, else 1\n",
        "train['Label'] = train['Label'].map({'BENIGN': 0}).fillna(1).astype(int)\n",
        "test['Label'] = test['Label'].map({'Benign': 0}).fillna(1).astype(int)\n",
        "\n",
        "# ========== 2. BUILD GRAPH ==========\n",
        "# Encode IPs as integer node indices\n",
        "all_ips = pd.concat([train['Source IP'], train['Destination IP'],\n",
        "                     test['Source IP'], test['Destination IP']]).unique()\n",
        "ip_to_idx = {ip: i for i, ip in enumerate(all_ips)}\n",
        "\n",
        "# Create edge index tensor for train\n",
        "edge_index_train = torch.tensor([\n",
        "    [ip_to_idx[src] for src in train['Source IP']],\n",
        "    [ip_to_idx[dst] for dst in train['Destination IP']]\n",
        "], dtype=torch.long)\n",
        "\n",
        "edge_attr_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(train['Label'].values, dtype=torch.long)\n",
        "\n",
        "# PyG Data object for training\n",
        "data_train = Data(edge_index=edge_index_train, edge_attr=edge_attr_train, y=y_train)\n",
        "\n",
        "# ========== 3. DEFINE GNN ==========\n",
        "class EdgeGNN(torch.nn.Module):\n",
        "    def __init__(self, edge_feat_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(edge_feat_dim, hidden_dim)\n",
        "        self.fc2 = torch.nn.Linear(hidden_dim, 2)  # Binary classification\n",
        "\n",
        "    def forward(self, edge_attr):\n",
        "        x = F.relu(self.fc1(edge_attr))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Instantiate model\n",
        "model = EdgeGNN(edge_feat_dim=edge_attr_train.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# ========== 4. TRAIN ==========\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data_train.edge_attr)\n",
        "    loss = loss_fn(out, data_train.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch%50 == 0:\n",
        "      print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ========== 5. PREPARE TEST GRAPH ==========\n",
        "edge_index_test = torch.tensor([\n",
        "    [ip_to_idx.get(src, -1) for src in test['Source IP']],\n",
        "    [ip_to_idx.get(dst, -1) for dst in test['Destination IP']]\n",
        "], dtype=torch.long)\n",
        "\n",
        "# Filter out any edges with unknown IPs (-1)\n",
        "valid_mask = (edge_index_test[0] != -1) & (edge_index_test[1] != -1)\n",
        "edge_index_test = edge_index_test[:, valid_mask]\n",
        "edge_attr_test = torch.tensor(X_test[valid_mask.numpy()], dtype=torch.float32)\n",
        "y_test = torch.tensor(test['Label'].values[valid_mask.numpy()], dtype=torch.long)\n",
        "\n",
        "# PyG Test Data\n",
        "data_test = Data(edge_index=edge_index_test, edge_attr=edge_attr_test, y=y_test)\n",
        "\n",
        "# ========== 6. EVALUATE ==========\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(data_test.edge_attr)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"=== Evaluation Results ===\")\n",
        "print(classification_report(data_test.y.cpu(), preds.cpu(), digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(data_test.y.cpu(), preds.cpu()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rnq-MtCT7ad",
        "outputId": "6e0e17f1-b9ff-4745-89f4-b7dc05487940"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7904\n",
            "=== Evaluation Results ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     1.0000    1.0000    1.0000   1907626\n",
            "\n",
            "    accuracy                         1.0000   1907626\n",
            "   macro avg     1.0000    1.0000    1.0000   1907626\n",
            "weighted avg     1.0000    1.0000    1.0000   1907626\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1907626]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPE9dwIIUHzz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}